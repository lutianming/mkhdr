#+TITLE: Project SI241: Creation of HDR images
#+AUTHOR: LU Tianming, TAI Yang
#+options: toc:t
#+LATEX_HEADER: \usepackage{amsmath}

\newpage

* Introduction
  In this project, we create HDR(High dynamic range) images from a set of low dynamic range images with different exposure times. The method in the project consists of two parts: radiance map reconstruction and tone mapping. Radiance map is based on the paper "Recovering high dynamic range radiance maps from photographs" by P. Debevec and J. Malik. And two tone mapping operators, based on Durand 2002 and E. Reinhard 2002 are implemented.

* Radiance Map Reconstruction
  It takes two steps to reconstruct the radiance map.
  1. Recovering the response curve
  2. Constructing the High Dynamic Range Radiance Map

** Recovering the response curve
   In a image, we get the pixel value /Z/ from a nonlinear function of the original exposure /X/ at the pixel. We call the function /f/. And the exposure /X/ is defined as the product of the irradiance /E/ and the exposure time \( \Delta t \). We denote the pixel value \( Z_{ij} \) where /i/ is the index of pixel in an image and /j/ is the index of exposure time \( \Delta t_{j} \). Then we get
   \[ Z_{ij} = f(E_{i}\Delta t_{j}) \]
   We assume that /f/ is monotonic, and we rewrite it as
   \[ f^{-1}(Z_{ij}) = E_{i}\Delta t_{j} \]
   Take the natural logarithm,
   \[ \ln f^{-1}(Z_{ij}) = \ln E_{i} + \ln \Delta t_{j} \]
   Define \(g = \ln f^{-1} \), then
   \[ g(Z_{ij}) = \ln E_{i} + \ln \Delta t_{j} \]
   We notice that recovering /g/ only need to recover finite number of \( g(z) \) since the input /Z/ only has finite values, from 0 to 255. Then we reformulate the problem to minimize the folling quadratic function.
   \[ \mathcal{O} = \sum\limits_{i=1}^{N} \sum\limits_{j=1}^{P}\left[ g(Z_{ij})-\ln E_{i} - \ln \Delta{t_{j}} \right]^{2} + \lambda \sum\limits_{z=Z_{min}+1}^{Z_{max}-1} g''(z)^{2} \]
   Where Z_{min} and Z_{max} are the least and greatest pixel values, /N/ is the number of pixels and /P/ is the number of photos with different exposure times. The value \lambda controls the smooth of the curve.

   Then we introduce a weighting function \( w(z) \):
   \[
   w(z) = \left\{ \begin{array}{rl}
   z - Z_{min} & \text{for } z \leq \frac{1}{2}(Z_{min}+Z_{max}) \\
   Z_{max} - z & \text{for } z > \frac{1}{2}(Z_{min}+Z_{max})
   \end{array} \right.
   \]

   This function is to ensure that the midway between Z_{min} and Z_{max} will have unit exposure.

   Then finaly the function becomes:
   \[ \mathcal{O} = \sum\limits_{i=1}^{N} \sum\limits_{j=1}^{P}
   \left\{ w(Z_{ij})\left[ g(Z_{ij})-\ln E_{i} - \ln \Delta{t_{j}} \right]\right\}^{2} + \lambda \sum\limits_{z=Z_{min}+1}^{Z_{max}-1} [w(z)g''(z)]^{2} \]

   As mentioned in the paper, it is unnecessary and computationally expensive to use all the pixels of images to recover the curve. So in our case, We take unifrom samples in the images and the number of samples can be ajusted.

   In the figure([[curve]]), we show some response curves from test images. We take 14*14 samples and the smooth factor is 50.
   #+caption: response curves
   #+name: curve
   [[./curve.jpg]]

** Constructing the radiance map
   After recovering the response curve /g/, we can use it to convert pixel values to radiance values. In the previous section, we get:

   \[ \ln E_{i} = g(Z_{ij}) - \ln \Delta t_{j} \]

   And for robustness, we can reuse the weighting function \( w(z) \) so that all the exposure times can be used. So, it becomes:

   \[ \ln E_{i} = \frac{\sum\limits_{j=1}^{P} w(Z_{ij})(g(Z_{ij} - \ln \Delta t_{j}))}{ \sum\limits_{j=1}^{P}w(Z_{ij})} \]

** Color
   For color images, The steps are just the same. We only need to recover the response curve and contruct the radiance map for all the RGB channels.

* Tone mapping
  Though we have the radiance map now, we still can not display the image in high dynamic range because all the screens , monitors and projectors only have a limited dynamic range. So we have to use the /Tone mapping/ method to approximate the appearance of HDR images in a medium that has limited dynamic range. And there are many different /tone mapping/ operators.

** Global operators
   They are non-linear functions based on the luminance and other global variables of the image. Once the optimal function has been estimated according to the particular image, every pixel in the image is mapped in the same way, independent of the value of surrounding pixels in the image. Those techniques are simple and fast.

   One simple global operator is just simply linearly mapping the radiance map into 0-255 to produce the result.
   \[ I = \frac{E - \min(E)}{\max(E) - \min(E)} * 255 \]
   We can also first map E to \( E/(E+1) \) before mapping to 255, thus
   \[ I = \frac{E}{E+1} * 255 \]
   But those operators are so simple that they cause a loss of constrast. We need some operators more accuracy.

*** Reinhard
    In our project, we implement a global operator based on the paper /Photographic tone reproduction for digital images/. Though it is a global operator, it has a good performance.

   First we calculate the luminance map from radiance map. For a color image with 3 channels:
   \[ L = 0.27R + 0.67G + 0.06B \]
   Where R, G, B is the radianca map value of different channels.
   We view the log-average luminance as a useful approximation to the key of the scene. This quantity \( \overline{L}_{w} \) is computed by:
   \[ \overline{L} = \frac{1}{N} exp\left( \sum\nolimits_{x,y} log(\delta + L_{w}(x,y)) \right) \]
   Where \( L_{w} \) is the "world" luminance for pixel \( (x, y) \) from radiance map. \delta which is 0.0001 in this project is a small value to avoid the singularity that occurs if black pixels are present in the image.
   \[ L(x, y) = \frac{a}{\bar{L}_{w}} L_{w}(x,y) \]
   We can change the value of /a/ to get different result. Then finally,
   \[ L_{d}(x, y) = \frac{L(x,y)}{1+L(x,y)} \]
   Then we need to recover the color from the output luminance. We use the method in the paper /Gradient domain high dynamic range compression/.
   \[ C_{out} = \left( \frac{C_{in}}{L} \right)^{s} L_{d} \]
   Where \( C_{in} = R, G, B \). The exponent /s/ controls the color saturation of the result image. According the paper, a value from 0.4 to 0.6 can produce satisfactory results. After getting /C_{out}/, we can then use simple operator to map it to [0, 255]. After that, we can make a gamma correction. But it is optional.

** Local operator
   The parameters of the non-linear function change in each pixel, according to features extracted from the surrounding parameters. In other words, the effect of the algorithm changes in each pixel according to the local features of the image. Those algorithms are more complicated than the global ones. But they can provide better performance.

   In this project, we implement the operator based on bilateral filter which is a non-linear, edge-preserving and noise-reducing smoothing filter for images.
   For this operator, we also need to make a mapping from radiance maps to luminance intensity. We follow the step provided by [[http://people.csail.mit.edu/fredo/PUBLI/Siggraph2002/][Durand]]:
   \[ intensity = 0.27R + 0.67G + 0.06B \]
   Intensity here is the same as luminance in the previeus section. Then

   \begin{align*}
   L_{input} &= \log(intensity) \\
   L_{base} &= Bilateral(L_{input}) \\
   L_{detail} &= L_{input} - L_{base} \\
   L_{output} &= L_{base}*c + L_{detail} - \max(L_{base})*c
   \end{align*}

   Where /c/ is the compression factor which equals to:
   \[ c = \frac{targetContrast}{\max(L_{base}) - \min(L_{base})} \]
   The value /targetContrast/ is 5 in this project. Then we recover colors from luminance. We use the same method mentions in the previeus section.

* Implementation and Usage
  We use Python with following frameworks to implment the project.
  + PIL(Python Imaging Library)
  + Numpy
  + matplotlib
  + OpenCV
  + pyside(GUI)

  The project provides both a command line interface and graphic interface.
  Most import parameters are ajustable, include:
  + radiance map construction
    + sample size
    + smooth factor
  + tone mapping
    + saturation
    + gamma
    + other operator specific parameters

* Results
  We apply our implementation to some public test images. And figure([[result1]]), figure([[result2]]), figure([[result3]]), figure([[result4]]) are the results. All the result HDR images are generated with the default parameters, that is:
  + sample size: 200
  + smooth factor: 50
  + saturation: 0.6

  For Durand operator, \sigma_{r} is 0.4 and \sigma_{d} is 100. For Reinhard operator, /a/ is 0.36.

  #+caption: result 1
  #+name: result1
  [[./result3.jpg]]

  #+caption: result 2
  #+name: result2
  [[./result4.jpg]]

  #+caption: result 3
  #+name: result3
  [[./result5.jpg]]

  #+caption: result 4
  #+name: result4
  [[./result6.jpg]]

* Conclusions
  From the results we can see that local operator can have a good performance but it need to be used carefully with parameter tuning. Simple global operators can have a good performance in some conditions. But the global operator /Reinhard/ has a performance as good as the local one.

  There are also some problems in the result. For example, in figure([[result1]]), when there is artificial light or an extremely bright part in the image, the HDR result of such part seems becom too bright and feel blue.

  What's more, the algorithm now only considers that all the original images are taken perfectly in the same position and angle. In other word, the algorithm only works when all the images are same and static. But this is difficult to achieve with a normal camera. It is common that there might be little shakes in the images even if you take multiple photos at the same position. So it will be better to improve the algorithm to work with such images.

* References
  1. Debevec, P. E., & Malik, J. (2008, August). /Recovering high dynamic range radiance maps from photographs/. In ACM SIGGRAPH 2008 classes (p. 31). ACM.
  2. Durand, F., & Dorsey, J. (2002, July). /Fast bilateral filtering for the display of high-dynamic-range images/. In ACM Transactions on Graphics (TOG) (Vol. 21, No. 3, pp. 257-266). ACM.
  3. Reinhard, E., Stark, M., Shirley, P., & Ferwerda, J. (2002, July). /Photographic tone reproduction for digital images/. In ACM Transactions on Graphics (TOG) (Vol. 21, No. 3, pp. 267-276). ACM.
  4. Fattal, R., Lischinski, D., & Werman, M. (2002, July). /Gradient domain high dynamic range compression/. In ACM Transactions on Graphics (TOG) (Vol. 21, No. 3, pp. 249-256). ACM.
